from pyspark.sql import SparkSession
from pyspark.sql.functions import col
from pyspark.sql.types import StructType, StructField, StringType, TimestampType, MapType
from main import extract_new_process_creation_logs

spark = SparkSession.builder.appName("EventIDExtraction").getOrCreate()

# Define schema
schema = StructType([
    StructField("@timestamp", TimestampType(), True),
    StructField("@metadata", MapType(StringType(), StringType()), True),
    StructField("event", StructType([
        StructField("kind", StringType(), True),
        StructField("provider", StringType(), True),
        StructField("outcome", StringType(), True),
        StructField("action", StringType(), True),
        StructField("created", TimestampType(), True),
        StructField("code", StringType(), True)
    ]), True),
    StructField("log", StructType([
        StructField("level", StringType(), True)
    ]), True),
    StructField("message", StringType(), True),
    StructField("host", StructType([
        StructField("name", StringType(), True)
    ]), True),
    StructField("ecs", StructType([
        StructField("version", StringType(), True)
    ]), True),
    StructField("agent", StructType([
        StructField("ephemeral_id", StringType(), True),
        StructField("id", StringType(), True),
        StructField("name", StringType(), True),
        StructField("type", StringType(), True),
        StructField("version", StringType(), True)
    ]), True),
    StructField("winlog", StructType([
        StructField("api", StringType(), True),
        StructField("opcode", StringType(), True),
        StructField("provider_guid", StringType(), True),
        StructField("provider_name", StringType(), True),
        StructField("process", StructType([
            StructField("pid", StringType(), True),
            StructField("thread", StructType([
                StructField("id", StringType(), True)
            ]), True)
        ]), True),
        StructField("channel", StringType(), True),
        StructField("event_id", StringType(), True),
        StructField("computer_name", StringType(), True),
        StructField("task", StringType(), True),
        StructField("event_data", MapType(StringType(), StringType()), True),
        StructField("record_id", StringType(), True),
        StructField("keywords", StringType(), True)
    ]), True)
])


def detect_process_termination(df):
    termination_logs = df.filter(col("winlog.event_id") == "4689")
    if termination_logs.count() > 0:
        print("Process termination detected.")
        termination_logs.show(truncate=False)
    else:
        print("No process termination detected.")

def detect_suspicious_network_activity(df):
    network_logs = df.filter(col("winlog.event_id") == "5156")
    if network_logs.count() > 0:
        print("Suspicious network activity detected.")
        network_logs.show()
    else:
        print("No suspicious network activity detected.")

def detect_credential_access(df):
    credential_logs = df.filter(col("winlog.event_id") == "5379")
    if credential_logs.count() > 0:
        print("Credential access detected.")
        credential_logs.show()
    else:
        print("No credential access detected.")

def detect_object_access(df):
    object_access_logs = df.filter(col("winlog.event_id") == "4663")
    if object_access_logs.count() > 0:
        print("Object access detected.")
        object_access_logs.show()
    else:
        print("No object access detected.")

def detect_permission_changes(df):
    permission_logs =  df.filter(col("winlog.event_id") == "4670")
    if permission_logs.count() > 0:
        print("Permission changes detected.")
        permission_logs.show()
    else:
        print("No permission changes detected.")

def detect_privilege_service(df):
    pservice_logs = df.filter(col("winlog.event_id") == "4673")
    if pservice_logs.count() > 0:
        print("Privilege service detected.")
        pservice_logs.show()
    else: 
        print("No privilege service detected.")

def detect_group_membership(df):
    group_logs = df.filter(col("winlog.event_id") == "4627")
    if group_logs.count() > 0:
        print("Group membership detected.")
        group_logs.show()
    else:
        print("No group membership detected.")

def detect_sec_grp_membership(df):
    sec_grp_logs = df.filter(col("winlog.event_id") == "4799")
    if sec_grp_logs.count() > 0:
        print("Security group membership detected.")
        sec_grp_logs.show()
    else:
        print("No security group membership detected.")

def detect_attempt_to_duplicate_handle_to_object(df):
    handle_logs = df.filter(col("winlog.event_id") == "4690")
    # handle_logs.show()
    if handle_logs.count() > 0:
        print("Attempt to duplicate handle to object detected.")
        handle_logs.show()
    else:
        print("No attempt to duplicate handle to object detected.")

# Correlation function
def correlate_logs(df):
    print("Starting log correlation...")
    detect_process_termination(df)
    detect_credential_access(df)
    detect_object_access(df)
    detect_permission_changes(df)
    detect_suspicious_network_activity(df)
    detect_privilege_service(df)
    detect_group_membership(df)
    detect_sec_grp_membership(df)
    extract_new_process_creation_logs(df)
    detect_attempt_to_duplicate_handle_to_object(df)

# Main function to process logs
def checkmalware(spark, file_path):
    df = spark.read.json(file_path, schema=schema)
    correlate_logs(df)
